# Environment parameters
help_func = False # whether to use helper function during node insertion process, which inserts node into best position in current partial tour, default value false
reward_sign = -1 # sign of the reward, default value -1 (makes sense since we want to minimize the tour length but select node with max Q-value)
reward_normalization = 'max' # factor for reward normalization, 'max': NUM_MAX, 'min': NUM_MIN, 'auto': num nodes, default value 'max'
fix_start_node = False

# GNN hyperparameters
net_type = 'AGNN' # specifies which net to use, S2VDQN needs embeddingmethod 3
max_bp_iter = 3 # number of aggregation steps in GNN, equals number of layers, default value 3
aggregatorID = 1 # 0:sum; 1:mean; 2:GCN; 3:edge weight based sum, default value 0
node_init_dim = 6 # number of initial node features, default value 6
edge_init_dim = 4 # number of initial edge features, default value 4
state_init_dim = 1 # number of initial state features, default value 1
node_embed_dim = 64 # dimension p for each vector embedding of the nodes in the graph, default value 64
edge_embed_dim = 64 # dimension q for each vector embedding of the edges in the graph, default value 64
state_embed_dim = 128
embeddingMethod = 3 # 0:no inclusion of edge weights, 1:inclusion of sum of edge weights per node, 2:S2V-DQN edge weight inclusion 3:Changjun edge embeding, default value 2
ignore_covered_edges = True # whether to ignore edges of which both adjacent nodes have already been selected, default value false
selected_nodes_inclusion = 1 # 0:no inclusion of selected nodes, 1:start and last selected node inclusion, 2:all selected nodes included, default value 2
focus_start_end_node = True # whether to specifically include start and end node embedding in the state and decoding process
state_representation = 1 # 0:concat state, 1:MHA state

# general training hyperparameters
IsHuberloss = false # whether to use huberloss as loss function during training, default value false
BATCH_SIZE = 64 # batch size during training, default value 64
initialization_stddev = 0.01 # variance of weight initialization, default value 0.01
MAX_ITERATION = 50000 # max training iterations, default value 150000
LEARNING_RATE = 0.001 # learning rate for gradient descent, default value 0.001
Alpha = 0.001 # weight of reconstruction loss, default value 0.001
save_interval = 300 # number of iterations after which the model is tested and saved, default value 300
num_env = 1 # num environments during training, default value 1
dropout_rate = 0.0

# training set specifications
g_type = 'tsp_2d' # one of 'tsp_2d', 'tsp', default value 'tsp_2d'
NUM_MIN = 20 # min dim of training/validation graphs, default value 15
NUM_MAX = 20 # max dim of training/validation graphs, default value 20
NN_ratio = 2.0 # percentage of neareast neighbors for graph sparsification, 2.0 for edge probability sparsification
n_generator = 1000 # number of graphs for each training graph generation cycle, default value 1000
train_path = 'data/train_sets/synthetic_n_20_200000'
train_scale_fac = 0.000001

# Decoder hyperparameters
decoder_type = 0 # 0:concat decoder, 1:attention decoder, default value 0
REG_HIDDEN = 32 # num neurons in the hidden layer of the decoder, default value 32

# search startegy
search_strategy = 'greedy' # 'beam_search', 'beam_search+', 'greedy'
beam_width = 64
test_batch_size = 512

# Q-learning hyperparameters
IsDoubleDQN = false # whether to use double DQN algorithm, default value false
N_STEP = 5 # number of steps in NDQN until the reward is observed, default value 5
GAMMA = 1.0 # decay rate of past observations, default value 1.
UPDATE_TIME = 1000 # when to take snapshots, default value 1000
eps_start = 1.0 # starting value of exploration chance, default value 1.0
eps_end = 0.05 # end value of exploration chance, default value 0.05
eps_step = 10000.0 # number of steps until eps_end is reached, default value 10000.0
MEMORY_SIZE = 150000 # size of the replay memory, default value 150000
one_step_encoding = False
use_edge_probs = True
probability_construction = False

# validation set info
valid_path = 'data/valid_sets/synthetic_nrange_20_20_100' # path to external validation samples in TSPLIB format, default value 'valid_sets/synthetic_nrange_10_20_200/'
valid_scale_fac = 0.000001 # sets the factor of scaling that is applied to all external validation samples --> transfo into (0,1) square, default value 0.0001
n_valid = 300 # number of graphs in validation set (only used if valid_path = None), default value 200

# (hyper)parameters for prioritized replay sampling
IsPrioritizedSampling = false # whether to use prioritized replay memory, default value false
epsilon = 0.0000001 # small amount to avoid zero priority, default value 0.0000001
alpha = 0.6 # [0~1] convert the importance of TD error to priority, default value 0.6
beta = 0.4 # importance-sampling, from initial value increasing to 1, default value 0.4
beta_increment_per_sampling = 0.001 # default value 0.001
TD_err_upper = 1. # clipped abs error, default value 1.