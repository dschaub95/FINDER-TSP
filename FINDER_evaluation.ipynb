{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('findervenv': conda)"
  },
  "interpreter": {
   "hash": "cac74b763dd6365b660360e42fb86b007d1646e45a2a765c06460ea0e8dba80b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/root/miniconda3/envs/findervenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/miniconda3/envs/findervenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/miniconda3/envs/findervenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/miniconda3/envs/findervenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/miniconda3/envs/findervenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/miniconda3/envs/findervenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/root/miniconda3/envs/findervenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/miniconda3/envs/findervenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/miniconda3/envs/findervenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/miniconda3/envs/findervenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/miniconda3/envs/findervenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/miniconda3/envs/findervenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from FINDER import FINDER\n",
    "from FINDER_utils import *\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tsplib95\n",
    "import networkx as nx\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'help_func': 1, 'net_type': 'S2V-DQN', 'max_bp_iter': 3, 'aggregatorID': 0, 'node_init_dim': 6, 'edge_init_dim': 4, 'state_init_dim': 1, 'node_embed_dim': 64, 'edge_embed_dim': 64, 'embeddingMethod': 3, 'ignore_covered_edges': 1, 'selected_nodes_inclusion': 2, 'IsHuberloss': 0, 'BATCH_SIZE': 64, 'initialization_stddev': 0.01, 'MAX_ITERATION': 30000, 'LEARNING_RATE': 0.0001, 'Alpha': 0.001, 'save_interval': 300, 'num_env': 1, 'g_type': 'tsp_2d', 'NUM_MIN': 15, 'NUM_MAX': 20, 'n_generator': 1000, 'decoder': 0, 'REG_HIDDEN': 32, 'IsDoubleDQN': 0, 'N_STEP': 1, 'GAMMA': 0.1, 'UPDATE_TIME': 1000, 'eps_start': 1.0, 'eps_end': 1.0, 'eps_step': 10000.0, 'MEMORY_SIZE': 150000, 'reward_normalization': 'max', 'reward_sign': 1, 'valid_path': 'valid_sets/synthetic_nrange_15_20_200/', 'valid_scale_fac': 0.0001, 'n_valid': 200, 'IsPrioritizedSampling': 0, 'epsilon': 1e-07, 'alpha': 0.6, 'beta': 0.4, 'beta_increment_per_sampling': 0.001, 'TD_err_upper': 1.0}\n",
      "Sucessfully loaded key 'help_func' from external config file!\n",
      "Sucessfully loaded key 'net_type' from external config file!\n",
      "Sucessfully loaded key 'max_bp_iter' from external config file!\n",
      "Sucessfully loaded key 'aggregatorID' from external config file!\n",
      "Sucessfully loaded key 'node_init_dim' from external config file!\n",
      "Sucessfully loaded key 'edge_init_dim' from external config file!\n",
      "Sucessfully loaded key 'state_init_dim' from external config file!\n",
      "Sucessfully loaded key 'node_embed_dim' from external config file!\n",
      "Sucessfully loaded key 'edge_embed_dim' from external config file!\n",
      "Sucessfully loaded key 'embeddingMethod' from external config file!\n",
      "Sucessfully loaded key 'ignore_covered_edges' from external config file!\n",
      "Sucessfully loaded key 'selected_nodes_inclusion' from external config file!\n",
      "Sucessfully loaded key 'IsHuberloss' from external config file!\n",
      "Sucessfully loaded key 'BATCH_SIZE' from external config file!\n",
      "Sucessfully loaded key 'initialization_stddev' from external config file!\n",
      "Sucessfully loaded key 'MAX_ITERATION' from external config file!\n",
      "Sucessfully loaded key 'LEARNING_RATE' from external config file!\n",
      "Sucessfully loaded key 'Alpha' from external config file!\n",
      "Sucessfully loaded key 'save_interval' from external config file!\n",
      "Sucessfully loaded key 'num_env' from external config file!\n",
      "Sucessfully loaded key 'g_type' from external config file!\n",
      "Sucessfully loaded key 'NUM_MIN' from external config file!\n",
      "Sucessfully loaded key 'NUM_MAX' from external config file!\n",
      "Sucessfully loaded key 'n_generator' from external config file!\n",
      "Sucessfully loaded key 'decoder' from external config file!\n",
      "Sucessfully loaded key 'REG_HIDDEN' from external config file!\n",
      "Sucessfully loaded key 'IsDoubleDQN' from external config file!\n",
      "Sucessfully loaded key 'N_STEP' from external config file!\n",
      "Sucessfully loaded key 'GAMMA' from external config file!\n",
      "Sucessfully loaded key 'UPDATE_TIME' from external config file!\n",
      "Sucessfully loaded key 'eps_start' from external config file!\n",
      "Sucessfully loaded key 'eps_end' from external config file!\n",
      "Sucessfully loaded key 'eps_step' from external config file!\n",
      "Sucessfully loaded key 'MEMORY_SIZE' from external config file!\n",
      "Sucessfully loaded key 'reward_normalization' from external config file!\n",
      "Sucessfully loaded key 'reward_sign' from external config file!\n",
      "Sucessfully loaded key 'valid_path' from external config file!\n",
      "Sucessfully loaded key 'valid_scale_fac' from external config file!\n",
      "Sucessfully loaded key 'n_valid' from external config file!\n",
      "Sucessfully loaded key 'IsPrioritizedSampling' from external config file!\n",
      "Sucessfully loaded key 'epsilon' from external config file!\n",
      "Sucessfully loaded key 'alpha' from external config file!\n",
      "Sucessfully loaded key 'beta' from external config file!\n",
      "Sucessfully loaded key 'beta_increment_per_sampling' from external config file!\n",
      "Sucessfully loaded key 'TD_err_upper' from external config file!\n",
      "WARNING:tensorflow:From /tmp/ipykernel_635/3462738274.py:2: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_635/3462738274.py:2: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_635/3462738274.py:2: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_635/3462738274.py:2: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_635/3462738274.py:2: The name tf.trace is deprecated. Please use tf.linalg.trace instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_635/3462738274.py:2: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/findervenv/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /tmp/ipykernel_635/3462738274.py:2: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_635/3462738274.py:2: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "2021-07-13 12:52:10.352525: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2021-07-13 12:52:10.377698: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3990990000 Hz\n",
      "2021-07-13 12:52:10.378150: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55764ddd5eb0 executing computations on platform Host. Devices:\n",
      "2021-07-13 12:52:10.378177: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2021-07-13 12:52:10.379465: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-13 12:52:10.392179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 12:52:10.392480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 970 major: 5 minor: 2 memoryClockRate(GHz): 1.253\n",
      "pciBusID: 0000:01:00.0\n",
      "2021-07-13 12:52:10.392711: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-07-13 12:52:10.393909: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-07-13 12:52:10.394889: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-07-13 12:52:10.395138: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-07-13 12:52:10.396788: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-07-13 12:52:10.398548: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-07-13 12:52:10.401853: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-07-13 12:52:10.402005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 12:52:10.402369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 12:52:10.402759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2021-07-13 12:52:10.402825: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-07-13 12:52:10.449331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-13 12:52:10.449355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2021-07-13 12:52:10.449364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2021-07-13 12:52:10.449597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 12:52:10.450282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 12:52:10.450568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 12:52:10.450815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3223 MB memory) -> physical GPU (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2)\n",
      "2021-07-13 12:52:10.451990: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55764e9fe380 executing computations on platform CUDA. Devices:\n",
      "2021-07-13 12:52:10.452011: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 970, Compute Capability 5.2\n",
      "WARNING:tensorflow:From /tmp/ipykernel_635/3462738274.py:2: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "tf.float32 has type DType, but expected one of: int, long, bool\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "tf.float32 has type DType, but expected one of: int, long, bool\n"
     ]
    }
   ],
   "source": [
    "config_path = 'best_models/tsp_2d/nrange_15_20_len_101203/config.txt'\n",
    "dqn = FINDER(config_path=config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = 'test_sets/synthetic_nrange_10_20_1000/'\n",
    "# data_dir = 'test_sets/synthetic_nrange_15_20_1000/'\n",
    "# data_dir = 'test_sets/synthetic_nrange_40_50_1000/'\n",
    "# data_dir = 'valid_sets/synthetic_nrange_10_20_200/'\n",
    "# data_dir = 'valid_sets/synthetic_nrange_15_20_200/'\n",
    "data_dir = 'test_sets/tsp_min-n=15_max-n=20_num-graph=1000_type=random/'\n",
    "data_dir_0 = 'test_sets/tsp_min-n=15_max-n=20_num-graph=1000_type=random/'\n",
    "data_dir_1 = 'test_sets/tsp_min-n=40_max-n=50_num-graph=1000_type=random/'\n",
    "data_dir_2 = 'test_sets/tsp_min-n=50_max-n=100_num-graph=1000_type=random/'\n",
    "data_dir_3 = 'test_sets/tsp_min-n=100_max-n=200_num-graph=1000_type=random/'\n",
    "test_dirs = [data_dir_0, data_dir_1, data_dir_2, data_dir_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1000it [00:05, 191.75it/s]\n",
      "Number of loaded test graphs: 1000\n",
      "nrange_15_20_iter_3300_len_101203.ckpt\n",
      "INFO:tensorflow:Restoring parameters from best_models/tsp_2d/nrange_15_20_len_101203/nrange_15_20_iter_3300_len_101203.ckpt\n",
      "  0%|          | 2/1000 [00:00<00:58, 17.20it/s]model sucessfully restored from file\n",
      "100%|██████████| 1000/1000 [01:04<00:00, 15.58it/s]\n",
      "1.0140715979543171\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "graph_list, fnames = prepare_testset_S2VDQN(data_dir)\n",
    "best_model_file, best_model_base_path, best_tour_length = find_best_model(dqn)\n",
    "# load model into Finder\n",
    "best_model = dqn.LoadModel(model_path=best_model_base_path+best_model_file)\n",
    "lengths, solutions, sol_times = run_test(dqn, graph_list)\n",
    "mean_approx_ratio = get_mean_approx_to_opt(data_dir, fnames, lengths)\n",
    "print(mean_approx_ratio)\n",
    "save_solutions(data_dir, fnames, solutions, best_model_file)\n",
    "save_lengths(data_dir, fnames, lengths, best_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_approx_ratios = []\n",
    "for data_dir in test_dirs:\n",
    "    # load test data\n",
    "    graph_list, fnames = prepare_testset_S2VDQN(data_dir)\n",
    "    best_model_file, best_model_base_path, best_tour_length = find_best_model(dqn)\n",
    "    # load model into Finder\n",
    "    best_model = dqn.LoadModel(model_path=best_model_base_path+best_model_file)\n",
    "    lengths, solutions, sol_times = run_test(dqn, graph_list)\n",
    "    mean_approx_ratio = get_mean_approx_to_opt(data_dir, fnames, lengths)\n",
    "    print(\"Mean approx ratio:\", mean_approx_ratio)\n",
    "    mean_approx_ratios.append(mean_approx_ratio)\n",
    "    save_solutions(data_dir, fnames, solutions, best_model_file)\n",
    "    save_lengths(data_dir, fnames, lengths, best_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_approx_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_list[0]\n",
    "length, solution, time_ = dqn.Evaluate(g=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([0, 6, 1, 11, 8, 9, 2, 7, 5, 10, 4, 3], 2.7711)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "solution, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether length calculation is correct\n",
    "def calc_tour_length(graph, solution):\n",
    "    tot_len = 0\n",
    "    for i in range(np.array(solution).shape[0]):\n",
    "        if i == np.array(solution).shape[0] - 1:\n",
    "            tot_len += graph[solution[i]][solution[0]]['weight']\n",
    "        else:\n",
    "            tot_len += graph[solution[i]][solution[i + 1]]['weight']\n",
    "    return tot_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node(graph, cur_sol, new_node):\n",
    "    cur_dist = 10000000.0\n",
    "    for i in range(0, np.array(cur_sol).shape[0]):\n",
    "        if i + 1 == np.array(cur_sol).shape[0]:\n",
    "            adj = cur_sol[0]\n",
    "        else:\n",
    "            adj = cur_sol[i + 1]\n",
    "        if cur_sol[i] == adj:\n",
    "            cost = graph[new_node][cur_sol[i]]['weight'] + graph[new_node][adj]['weight']\n",
    "        else:\n",
    "            cost = graph[new_node][cur_sol[i]]['weight'] + graph[new_node][adj]['weight'] - graph[cur_sol[i]][adj]['weight']\n",
    "        if cost < cur_dist:\n",
    "            cur_dist = cost\n",
    "            pos = i + 1\n",
    "    cur_sol.insert(pos, new_node)\n",
    "    return  cur_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_helper_tour(g):\n",
    "    cur_sol = [0]\n",
    "    rem_nodes = list(np.arange(g.number_of_nodes()))\n",
    "    rem_nodes.remove(0)\n",
    "    tour_length = 0\n",
    "    while np.array(cur_sol).shape[0] < g.number_of_nodes():\n",
    "        if np.array(rem_nodes).shape[0]-1 == 0:\n",
    "            rand_idx = 0\n",
    "        else:\n",
    "            rand_idx = np.random.randint(0, np.array(rem_nodes).shape[0]-1)\n",
    "        new_node = rem_nodes[rand_idx]\n",
    "        tour_length += add_node(g, cur_sol, new_node)\n",
    "        rem_nodes.remove(new_node)\n",
    "    return tour_length, cur_sol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_result = -np.inf\n",
    "min_result = np.inf\n",
    "for i in range(100):\n",
    "    help_lengths = []\n",
    "    for graph in graph_list:\n",
    "        help_lengths.append(calc_helper_tour(graph)[0])\n",
    "\n",
    "    true_lengths = None\n",
    "    with open(data_dir+'lengths.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [float(line.split(':')[-1].strip()) for line in lines]\n",
    "    true_lengths = lines\n",
    "    result = np.mean([length[0]/length[1] for length in zip(help_lengths, true_lengths)])\n",
    "    if result < min_result:\n",
    "        min_result = result\n",
    "    if result > max_result:\n",
    "        max_result = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0291948212594315\n1.0353626379176066\n"
     ]
    }
   ],
   "source": [
    "print(min_result)\n",
    "print(max_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5.9577"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": []
  }
 ]
}